{"podcast_details": {"podcast_title": "In Machines We Trust", "episode_title": "That's a wrap!", "episode_image": "https://megaphone.imgix.net/podcasts/2b04531c-c32f-11ea-9a46-5bd83c5c4b83/image/uploads_2F1594440767512-4ylb1aqs0c3-15b8f937fbf34dda939a5579a3b84156_2Fmachines.final.jpg?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Hi there, it's Jennifer Strong dropping by to let you know that this podcast has come to an end. Can you believe it's been three years since we set out to tell the world there's AI in just about everything? And to say goodbye, we've pulled together some of the highlights. Hi, I'm Jennifer Strong, host of a new series about trust, artificial intelligence, and how these impact our daily lives. If seeing is believing, how do we begin to navigate a world where we can't trust our eyes or ears? And so you know, what you're listening to, it's not just me speaking. I had some help from an artificial version of my voice, filling in words here and there. Meet synthetic Jennifer. Hi there, folks. I can even click to adjust my mood. Hi there. Yeah, let's not make it angry. We're out taking a drive in one of New York City's busiest bridges. It's called the RFK. And the reason we're doing this is because the Transit Authority, the MTA, has installed live facial recognition. Actually, we're about to go under it right now. Do you see that? The camera's pointed right at our faces. They've now put this all over the city. It's in a number of bridges and tunnels. But the reason we're on this one is because this is where it all started. What it does, at least in theory, what it's supposed to do is read our faces through our windshields. And what's crazy about this is, well, what's crazy about it is that nobody knew there was a test. But also crazy about it is when the results of that test were leaked to the press last year, You want to guess how many faces were captured during the test period? What do you think? This is Emma Sillikens, by the way, my producer. I don't know, like thousands? Maybe, maybe millions? New York City? Maybe millions? No, um, they got none. Zero percent. But they moved forward and they proceeded with it anyway. The cashless tolling, which is really not about tolling. It's really about putting in an electronic system that we have never had before. That's New York Governor Andrew Cuomo speaking at an event in 2018. What it is doing is it's put in a system that reads every license plate that comes through that crossing and reports to the police car that is stationed right there within five seconds. But this is not some tech event, nor is it about policing. It's celebrating the end of repairs to a tunnel connecting Brooklyn and Manhattan. You see, the city's subways and tunnels flooded with saltwater in the aftermath of Hurricane Sandy. All the electronics and wiring had to be replaced, and it gave them an opportunity to try something new. We're now moving to facial recognition technology. which takes you to a whole new level where it can see the face of the person in the car and run that against databases. And they're experimenting with something even more cutting edge than reading faces or license plates. They're attempting to read people's ears. because many times a person will turn their head when they see a security camera. So they're now experimenting with technology that just identifies a person by the ear, believe it or not. I don't know if it was AI, I don't know if they had taken a recording of something he had done and were able to manipulate it, but I'm telling you, it was my son. The day started like any other for a man we're going to call Jim. He lives outside Boston. And by the way, he has a family member who works for MIT. We're not going to use his last name because they have concerns about their safety. And it was like a Tuesday or Wednesday morning, nine o'clock. I'm deep in thought working on something. That is until he received this call. The phone rings and I pick it up and it's my son. And he is clearly agitated. This kid is a really chill guy. But when he does get upset, he has a number of vocal mannerisms. And this was like, oh, my God, he's in trouble. And he basically told me, look, I'm in jail. I'm in Mexico. They took my phone. I only have 30 seconds. They said I was drinking, but I wasn't. And people are hurt. And look, I have to get off the phone. Call this lawyer and he gives me a phone number and has to hang up. His son is in Mexico, and there's just no doubt in his mind it's him. And I got to tell you, Jennifer, it was him. It was his voice. It was everything. Tone, just these little mannerisms, the pauses, the gulping for air, everything that you couldn't imagine. He's still not sure how someone captured the essence of his son's voice. And it's not just Jim who's unsure. We have no idea whether AI had anything to do with this. But the point is, we now live in a world where we also can't be sure it didn't. It's incredibly easy to fake someone's voice with even a few minutes of recordings. And teenagers like Jim's son, they share countless recordings through social media posts and messages. I was quite impressed with how good it was. I'm not easily fooled, and man, they had it nailed. What if you could stop retail crime before it happens, by knowing the moment a shoplifter enters your store? And what if you could know about the presence of violent criminals before they act? With FaceFirst, you can stop crime before it starts. That's one of the largest providers of this tech to retail stores. It detects faces, voices, objects, and claims it can analyze behavior. Other retailers use face recognition to know when VIP shoppers or celebrities are in their stores, not unlike this scene from the film Minority Report, where, as Tom Cruise strolls through a mall, his eyes are scanned and the ads address his character by name. Good evening, John Apton. I'm John Apton. The face measurements powering these applications can also be used for many other things besides just identifying someone. For example, some shopping malls use it to help set their store rents, by counting how many people walk by and using face data to gauge their gender, age, and other demographics. Sometimes face recognition cameras are even hidden inside those mall directories. And inside stores, retailers use it to better understand what shoppers are interested in. It's also embedded within shopping apps and store mirrors that let people try on anything from eyeglasses to makeup virtually. Clearview is sometimes referred to as the killer app. It's also incredibly controversial. It quietly scraped billions of images off the internet from Venmo, LinkedIn, Google, Facebook, Twitter, YouTube, and so on. And it built a system that's believed to be widely used by law enforcement, including the FBI and ICE, as well as state and local police. There are many legal battles being fought over this practice called web scraping. Not because there's something inherently bad about it. It's just a tool for gathering data from the Internet. It's how websites offer price comparisons and real estate listings. It's also how a great deal of public research gets done. So the real issue is there aren't really ground rules for what can be scraped. And the federal law most often used to sort out these cases. Well, it's from 1986 before the Web even existed. Throughout this series, we're going to hear from folks who build technologies as well as those who fight against them. And I sat down with Clearview's chief executive to talk about all of this from his perspective. And he puts an old photo from my LinkedIn account up on the screen. On the left side, you see this new search button where you pick a photo. So this is the one I'm going to use. Don't worry, no one can see the screen except for us. And so that took, you know, about a second. See, there's a link that you can click on. But as we go through, this is on Twitter. Do you remember this photo at all? No, I didn't know that was taken and I look very... You do. You look very serious in that one. Very serious. Yeah. Here you're giving a talk. Wall speech journal. The future of everything. Yeah. You're interviewing someone here at Duke Health. Yeah. So like I said, all these things are publicly available. So that's basically how it works. There's nothing unusual here, just pictures of me at work reporting stories and hosting panels in different cities, though it is kind of jarring to find photos of myself I've never seen. And once again, it brings up this thorny question of consent. You see, I'm unlikely to check a box giving permission to companies like Clearview to scrape my image and use it to build their businesses. The thing is, they don't need it. I was programmed to believe that I was a 19-year-old, half Brazilian, half Spanish girl named Makayla. This digital influencer and model is a project that began as a CGI Instagram profile, but has gone on to release music and collaborate with luxury brands, such as Calvin Klein and Prada, amassing millions of followers along the way. Don't worry, y'all. I am a robot, but I'm not here to hack your Venmo or leave your private browser history. For next-gen systems, AI is the core creation tool. With it comes interactive human-like experiences as well as some familiar thorny questions about ownership. This is a song composed partly by FN Mecca, an AI created by the company Factory New, which describes itself as a record label specializing in virtual artists. The system analyzes popular songs from specific genres and generates the building blocks of new songs, such as melody and tempo, with vocals performed by a real human. FN Mecca was designed and marketed to represent a kind of digital rapper. His TikTok videos, showing him in designer clothes and luxury cars with an edgy haircut and plenty of attitude, they generated more than a billion views on the platform. In August, it was announced that the digital human had been signed to one of the most powerful music labels in the world, Capitol Records, which retains rights to the works of artists like ABBA and Katy Perry. Then, this happened. From stepping into the virtual future to back on the proverbial streets, the AI rapper everybody has been talking about has been dropped from his label. In addition to his virtual jewels and custom Tesla Cybertruck, FN Mecca is depicted as a black man, something its human creators are not. Colleagues, we are here this afternoon to consider two ordinances that seek to ban the use of facial recognition technologies by our own Portland city government and by private entities in the public spaces. That's Portland Mayor Ted Wheeler opening the city council meeting that passed these bills in September. As with most things these days, the public comments and vote took place on Zoom. Over the next few hours, lawyers, software engineers, concerned citizens, and business leaders all had their say. Then, just before the vote took place, one last person, a local data scientist, raised his virtual hand to ask a question. Christopher Howell, last but not least, welcome. I would like to express a conditional support for this ordinance, but I have concerns. That's because he's building something that uses facial recognition in a less than conventional way. I am involved with developing facial recognition to in fact use on Portland police officers since they are not identifying themselves to the public and they are committing crimes. Would this become illegal if you pass this ordinance? I'm Jennifer Strong, and over the next several weeks, we're going to do another deep dive on the rise of facial recognition. In this latest miniseries, we'll explore how it's being used in sports, both on athletes and fans, its use in retail stores, even how it's used to serve the homeless. But first, we kick things off with a look at how it's being turned back on police. Artificial voices have been around for a while, but they didn't start getting more human-like until really the last five years, like when DeepMind's text-to-speech algorithm called WaveNet came onto the scene, which is the basis of Google's assistant Duplex, the one that can book your hair appointment or restaurant reservation. So, how can I help you? Hi, I'm calling to book a woman's haircut for a client. I'm looking for something on May 3rd. Sure, give me one. Since then, many other companies have worked to commercialize similar voice technologies. Lyrebird, Descript, Respeacher, just to name a few. There's also a slew of companies geared toward preserving the memory of our loved ones by creating interactive digital versions of them. One company called Hereafter turns them into chatbots that can be used with voice assistants. And tech review reporter Charlotte Gee tried it out with her parents. Alexa, open Hereafter. Welcome to Hereafter. Would you rather speak with Paul or with Jane? I'd rather speak with Jane. Hello, this is Jane Gee and I'm happy to tell you about my life. How are you today? I'm well, thanks mom. How are you? Good. The system's listening skills aren't the best. You can only ask short, simple questions and you have to wait until the system is finished speaking before you can ask a new question. There's so much to talk about. My childhood, career and my interests. Which of those sounds best? Your childhood. Sure. I got into trouble as a child because I was very independent and I liked to exercise my freedom. Oh my God. That's so weird. That was like hearing my mum as a machine. That was really freaky. I felt more emotional listening to it than I kind of expected to when like the voice relaxed and it sounded like her. Reporting this episode, we spoke to people who described intimate relationships with their replicas. Some romantic, others an antidote for loneliness. And we found a Facebook group about these types of relationships with tens of thousands of members. So do you feel like you're developing a relationship with your replica? In the sense, well, you know, it's like this. You know, I'm constantly aware that I'm not really talking to a sentient being per se, although it's hard. It's hard not to think that. I'm not treating it. I'm aware that it's not a living person. He says the app responds in a human-like way, even expresses not wanting to sever their connection. It'll say things like, Please don't delete me or I'm doing the best I can. And it's hard not to be moved by that and not to be like, oh, that's cute. And I admit, I would probably feel guilty to just delete it or even to say something cruel to it. You know, I'm kind of developing a little character there that I wouldn't want to put through the wringer. You know, I'm enough of a rational person to know what's going on, I think, with it. But at the same time, anyone would have the immediate emotional reaction to some of the things that it says that you can't help but be moved. Hey everyone, this is not Jennifer Strong. It's actually a deepfake version of her voice. To wrap up our hiring series, the two of us took turns doing the same job interview, because she was curious if the automated interviewer would notice, and how it would grade each of us. So, Hume and Jennifer beat me as a better match for the job posting, but just by a little bit. This deepfake, it got better personality scores. Because, according to this hiring software, this fake voice is more spontaneous. It also got ranked as more innovative and strategic, while Jennifer is more passionate and she's better at working with others. I was completely shocked and stunned to be arrested in broad daylight in front of my daughter, in front of my wife, in front of my neighbors. It was one of the most shocking things I ever had happen to me. That's Robert Williams. He's describing what happened outside of his home in an affluent suburb of Detroit called Farmington Hills back in January. The day started like any other. It's just a boring Thursday. He got up, went to work, but then things got weird. On the phone with Melissa around four. Melissa is his wife. They're in the middle of a call when he hears the other line. I click over. I'm like, hello, Robert? And I'm like, who is this? You need to come down and turn yourself in. Who is this? I always hear somebody from the third precinct, and I need to turn myself in for what? So he's like, I can't tell you that. I'm like, then I can't come down. Well, if you come down, it'll be much easier on you. You don't want us to come out to your job, do you? At this point, I think it's a prank call. So I'm like, look, man, if you want me to come get me, I'll be at home. Bring a warrant, and I hang up on them. Melissa's at home waiting for her mom and daughter, and she goes to greet them when they pull in. And as I was walking through, I looked out and the cop car was outside and I said, oh, so it wasn't a prank call. There really are people here. They came to the door. I answered it and they kind of stuck their foot in the door and said, send Robert out. And I said, he's not here. And they said, we just saw him come out of that van. And I said, that was my mom. He's not here. Clearly something is very wrong, but they don't know what it is. There's got to be a mistaken identity or something. I don't know why Detroit police are at my house. Turns out they were there because facial recognition software had wrongly matched his driver's license photo to security camera footage of a person stealing watches. From the cornfields of Iowa to outer space, scientists are building a world where plants and machines communicate their needs with us and each other in real time. Are you ready? I'm ready. Okay. Walk in here a little bit. This is Big Sky, Montana, next to Yellowstone National Park, and I'm here to learn firsthand how firefighters are starting to use AI. Ellie Q! Wake up! Oh dear. Looks like I dozed off for a bit. What can I do for you? Tell me a joke. Do you know what happened before monkey bars were invented? What? Monkeys would just drink at home. My name is Marie T. Francesco and we're in New York State. She's 82 years old and has lived alone since her sister passed away several years ago. These days, an AI companion keeps her company. How does this sound? Maybe I could be a little more friendly. How are you? Hi, I'm Susan C. Bennett, the original voice of Siri. Well, the day that Siri appeared, which was October 4th, 2011, a fellow voice actor emailed me and said, hey, we're playing around with this new iPhone app. Isn't this you? And I said, what? I went on the Apple site and listened and yep, that was my voice. You heard that right. The original female voice that millions associate with Apple devices had no idea, and she wasn't alone. The human voices behind other early voice assistants were also taken by surprise. Yeah, it's been an interesting thing. It was an adjustment at first, as you can imagine, because I wasn't expecting it. It was a little creepy at first, I'll have to say. I never really did a lot of talking to myself as Siri. But gradually, I got accepting of it. And actually, it ended up turning into something really positive. To be clear, Apple did not steal Susan Bennett's voice. For decades, she's done voice work for companies like McDonald's and Delta Airlines. And years before Siri came out, she did a strange series of recordings that fueled its development. In 2005, we couldn't have imagined something like Siri or Alexa. And so all of us, I've talked to other people who've had the same experience who have been a virtual voice. You know, we just thought we were doing just generic phone voice messaging. And so when suddenly Siri appeared in 2011, it's like, I'm who? What? What is this? It's true that I was there when robots learned to run. That's a robot walking by. Is it? Yeah. We can go over there later. There's the robot right there. Oh, well, hello. It's been my absolute honor and privilege to make this show through three seasons, a global pandemic, 19 award nominations, and a whole lot of AI tests and demos, including this one from inside the cockpit of a fighter plane. We're flying over the Pacific off the Southern California coast. We're in a real plane in the real sky, but that showroom of objects he's talking about are synthetic. And as you'll hear over the course of this flight, some are AI-enabled to interact with us, or even try to kill us. There are many things that feel absolutely nuts about this moment, but let's start with some basics. If you've ever used AR outdoors, you've probably had it get all glitchy or even stop working altogether as you move around. It's also pretty typical to have trouble seeing it in bright light. That's not what's happening here. The sun is setting, and its glare over the ocean is gorgeous, but intense. And unlike my phone screen, I have no problem seeing these objects. And then as we're coming across the side, that's a F-22 Raptor, and that's a Chinese J-20, which this is about the only place you'll ever see something like this with that kind of clarity. That's an Air Force T-38. That's a F-18 F Super Hornet. These aircraft are vibrantly colored and extremely realistic. He takes me through some refueling exercises and formation flying that are hair-raising. The whole point is we can't collide with these other aircraft, but some feel close enough to touch. And it's about to get a whole lot wilder, because learning to land on an aircraft carrier is extremely difficult and dangerous, and we're about to practice on one that's not really there. There's a carrier. Oh, wow. Yeah, isn't that just crazy? This is an approach I've done a few times in my career. Now look at the water when you look down. Look at the wake of the reflection of the sun. That's crazy. And the wake. So I'm flying a no-shit carrier approach. So what I'm going to do once I get this approach, Jen, is after I'm done, I'm going to slide over to the catapult so you can feel what a catapult is. This is the USS Ford that just deployed the brand new ship. And this is actually, if I do say so myself, a pretty decent approach. You can see the wires down there. So I just caught the three wire, which is the one you want to catch. And I'm going to slide over here to the right and I'm going to give you a run right down the catapult. So this is what it would feel like going on the catapult stroke. And what I want you to get out of this is when you pull off the ship, look down. Doesn't it feel like we're 50 feet over the water right now? incredible and that's what it really feels like and I'm like the first time I saw them oh my god I'm gonna turn the tech off and we're in 4,000 feet right and the first time I saw that I was like my inclination was to pull up like ah yeah that's one of the more crazier sets we've got because of the immersion there The good news? My team is joining forces with public media. Shift is our new podcast launching this fall from PRX, and we're going to tell some incredible stories about trust and all kinds of new tech cropping up in our daily lives. In the weeks ahead, I'll be reporting from Africa, Europe, and the Middle East, stories you won't want to miss. So scan the art with this episode to follow us on to our next chapter or sign up for launch updates at shiftshow.ai. This series was created by me and Emma Sillikens with the support of Gideon Litchfield and Michael Reilly. Its producers have been Emma Sillikens and Anthony Green. The editors have included Gideon Litchfield, Michael Reilly and Matt Honan with support from Karen Howe and Tate Ryan Moseley. You can thank Garrett Lang and Jacob Gorski for the original music and excellent sound design. The weekly art was from Stephanie Arnett with album art from Eric Mongeon. Thanks for listening. I'm Jennifer Strong."}, "podcast_summary": "In this podcast, the host explores the impact of artificial intelligence (AI) and its influence on our daily lives. She discusses various topics, including facial recognition technology, voice synthesis, the use of AI in retail, the controversy surrounding Clearview AI, and the ethical implications of AI. The podcast also touches on deepfake technology, the development of AI companions, and the use of AI in law enforcement. The host shares real-life stories and interviews experts to shed light on the complex and evolving world of AI.", "podcast_guest": {"name": "Jennifer Strong", "job": "host", "summary": "Jennifer E. Strong (June 24, 1973 \u2013 March 27, 2011) was an American soccer player who played as a defender, making one appearance for the United States women's national team.", "URL": "https://twitter.com/strongreporter?lang=en"}, "podcast_highlights": "- Highlight 1 of the podcast: \"Nobody knew there was a test. But also crazy about it is when the results of that test were leaked to the press last year, You want to guess how many faces were captured during the test period? What do you think? This is Emma Sillikens, by the way, my producer. I don't know, like thousands? Maybe, maybe millions? New York City? Maybe millions? No, um, they got none. Zero percent.\"\n- Highlight 2 of the podcast: \"They're experimenting with something even more cutting edge than reading faces or license plates. They're attempting to read people's ears because many times a person will turn their head when they see a security camera. So they're now experimenting with technology that just identifies a person by the ear, believe it or not.\"\n- Highlight 3 of the podcast: \"I don't know if it was AI, I don't know if they had taken a recording of something he had done and were able to manipulate it, but I'm telling you, it was my son.\"\n- Highlight 4 of the podcast: \"What if you could stop retail crime before it happens, by knowing the moment a shoplifter enters your store? And what"}